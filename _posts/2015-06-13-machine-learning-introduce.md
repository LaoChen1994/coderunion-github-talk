---
layout: post
title: "深度学习三十年创新路（转）"
date: 2015-06-13 10:07:00
tag: 
categories: 机器学习
---

* content
{:toc}

原文地址：[http://36kr.com/p/533832.html](http://36kr.com/p/533832.html)

![](http://e.36krcnd.com/nil_class/840ecb9c-8d2d-470c-9a2a-e8ca46918c88/neural_net_bio.jpg!heading)

> 编者注：深度学习火了，从任何意义上，大家谈论它的热衷程度，都超乎想象。但是，似乎很少有人提出不同的声音，说深度学习的火热，有可能是过度的繁荣，乃至不理性的盲从。而这次，有不同的想法出现了。

本篇文章来自依图科技 CEO Leo的投稿，依图科技是一家专注研究CV（Computer Vison，计算机视觉）的以技术驱动的创业公司，Leo自己也在这一领域有深入研究，因此这次写下这篇文章，希望回顾一下深度学习三十年的创新之路。

近期Nature杂志刊登了Lecun、Bengio、Hinton的深度学习(deep learning)文章，是对最近深度学习火爆进展的总结，也是对他们三十年专注突破精神的最佳肯定。

深度学习火到什么程度呢？据我所知，在工业界，Google、Facebook、微软、百度、腾讯以及其它创业公司，没有一家公司不用深度学习可以做到顶级的智能识别实用精度（语音识别、人像识别等）。深度学习的广泛应用，让它载入史册，可以比肩最近人工智能领域的图灵奖工作--哈佛教授 Leslie Valiant的可学习性理论（2010年图灵奖，90年代初在此思想下诞生了著名的 Boosting 算法)、 UCLA教授 Judea Pearl 的基于概率推断的人工智能（2011年图灵奖，90年代末开始基于此思想的图模型风靡学术界）。 

![](http://a.36krcnd.com/nil_class/14a406cf-b36d-4946-b425-534f84143442/yitu.jpg)

上图为Harvard教授 Leslie Valiant 

![](http://a.36krcnd.com/nil_class/a272bb30-d43d-461d-82d3-795640f9109a/_____2015-06-15___8.49.22.png)

UCLA教授 Judea Pearl

我时常和业内人士交流 ，包括硅谷的工程师、研究员（图像分类、广告推荐等），风险投资者，美国学术界的教授，还有在创业公司的和在学校实验室做研究的清华、交大学生。大家对深度学习的历史背景缺乏全面细腻的了解，甚至有些盲从。

在我创业前，深度学习还没“火”，我在Yann Lecun的实验室呆了一年，研究图模型和深度学习的关系——当时对两个体系都深刻理解的人几乎没有。而在本该功利的创业环境里，到目前为止，我们团队还未使用深度学习，显得有些“另类”甚至“落伍”，所以带着这样熟悉又陌生的心情，今天想分享一下自己的体会，算是对深度学习以及Hinton和Lecun的三十年创新之路的致敬。

首先，来介绍下Deep Learning的主要人物背景：

Geoff Hinton是深度学习学派的祖师爷，老爷子腰椎不好，经常得站着写代码到夜里一点，不能坐飞机，得坐火车从东边到西边去开会。

![Image title](http://a.36krcnd.com/nil_class/a7ed1c96-e13a-4abd-8c8b-3250622e3b7d/_____2015-06-15___8.51.12.png)

Geoff Hinton，deep learning 学派创始人之一

Yann Lecun 是 Geoff Hinton 三十年前的弟子。最近深度学习应用于智能理解特别广泛的模型是卷积神经网（ConvNet），就是 Yann Lecun 发明的 / 命名的。在学术上，这和传统的深度学习其他的模型有显著性差异 —— 我甚至认为这是思想性的巨大差异（世界可学性的假设）。

![Image title](http://a.36krcnd.com/nil_class/b2dc93cd-67e0-4081-bcd0-9a90106f4fbc/_____2015-06-15___8.53.28.png)

上图右为Yann Lecun，卷积神经网的发明者，Geoff Hinton的弟子

Andrew Ng 是 Michale Jordan（ Berkeley 教授，图模型的泰斗）的明星弟子，Andrew 独立后，在Stanford,、Google 和 Baidu 做的反而是deep learning （有点武当弟子学了少林，或者少林弟子学了武当的意味）。后来做了网络公开课程Coursera后名声大噪，意义大大超越了其学术界的地位和范畴。

![Image title](http://a.36krcnd.com/nil_class/bc305d3d-3541-4522-9368-f333a13f909a/_____2015-06-15___8.54.42.png)

 上图为吴恩达（Andrew Ng），百度首席科学家，在线教育平台coursera的创始人

历史究竟发生了什么? 深度学习为什么突然火了？

标志性事件是，2012年底，Geoff Hinton的博士生Alex Krizhevsky、Ilya Sutskever（他们研究深度学习时间并不长）在图片分类的竞赛ImageNet上，识别结果拿了第一名。其实类似的比赛每年很多，但意义在于，Google团队也在这个数据集上做了测试（非公开的，Google没有显式参加学术界的“竞赛”），用的也是深度学习，但识别精度比Geoff Hinton的团队差了很多，这下工业界振奋了。

这个“Google团队”的特殊意义在于，不同于其他Google团队，这个项目受到Google足够的战略级重视，有着世界级的明星领导者，包括 Andrew Ng，还有 Google 神人 Jeff Dean（他们在深度学习领域已投入很多，并到处宣讲他们的战果），以及业界无法企及的硬件和数据资源支持。我想，如果没有这样巨大反差，深度学习还不会得到这么快的传播和认可（当时的学术界还不知道Google内部的测试成绩，只知道Geoff Hinton得了第一，击败了另一个学术界顶级的Oxford团队；甚至今天，很多人还不知道这段历史）。两个“小毛孩”打败了业界神话。到这里，Google投入产出并不有说服力，甚至是可耻的。

工业界似乎不需要、也不该关心面子。紧接着，巨头的垄断游戏开始了。在机器学习方面顶级年度会议（NIPS），Google竞价超过了微软等其他公司，收购了Alex Krizhevsky、Ilya Sutskever 和 Geoff Hinton 刚刚注册几个月的公司，好像是5000万美元买了三个人的部分时间。现在，Google 做不好的人可以正式拉着 Geoff Hinton 聊天了；Facebook作为回应，挖了Yann Lecun，让他在纽约领导成立了 Facebook AI lab；Andrew Ng则离开Google去了百度。

从“硬”结果来说，其实此时的百度做得不会比过去的 Google 差，但“软”名声还是因此提高很多：相比于Google X, Facebook AI lab, Google Brain等，“深度学习研究院”这个用算法命名部门的主意得要“魄力”的。后来Yann Lecun组的学生出来了一半，陆续开了几家深度学习的创业公司，其中一家早被 Twitter 收购。另外一些，加入了 Facebook 和 Google 。估计深度学习给 Geoff Hinton和 Yann Lecun 的组带来了近十个千万富翁。

但更有意思的是（很有启发性并值得思考），Alex Krizhevsky 和 Geoff Hinton的竞赛用的正是 Yann Lecun 发明的卷积神经网，但结果刚出来时（实现细节还没有公布），Yann Lecun和他的NYU实验室成员甚至没法重复Geoff Hinton的结果。自己发明的算法，使用结果不如另外一个组。这下炸了锅，Yann Lecun开了组会，反思的主题是“为什么过去两年我们没有得到这样的成绩” 。

高手过招，Idea is cheap; The devil is in the details （有想法很廉价；魔鬼在细节处）。想法其实很重要，但只能区分高手和普通人。高手都有想法，但谁才能创造历史呢？Yann Lecun 这样的实验室需要反思什么呢？先看看他们有些什么吧。我经历过巅峰时期的微软亚洲研究院（十五年前，这里的实习生只能是名校的各系第一名）、UCLA (排名10名左右)、MIT AI lab (计算机专业第一名)，实验室的茶歇时间 Tea Time, 过道挤满了顶级会议的最佳论文获得者---NIPS, CVPR等 。基于以上经验，我先介绍一下 Yann Lecun 实验室的过人之处。

Yann Lecun上课教授和使用的是他自己写的语言Lush，用来替代 matlab（很方便描述矩阵运算、图像处理等）、python在科学研究的功能；他的团队三十年如一日的专注于神经网络的研究，从不随波逐流，课题覆盖卷积神经网的方方面面。有的博士生聪明数学好，非常敏感于卷积神经网模型的深刻理解；有的博士生专注于结构参数的行为分析（多少层啊之类）；有的博士生研究在不同数据分布（应用场景下）的表现，比如字母识别、图像分类、物体检测、场景分类等。

这样的学术坚持，是在怎样的艰难背景下呢？人工智能领域，神经网络思想在80年代末开始衰落，之后分别经历了几个划时代的图灵奖级工作的兴起，统计学习理论（带来支持向量机 SVM 算法），可学习理论(带来 Boosting 算法)，概率推断（图模型，graphical model）几乎垄断了过去的三十年。在之前提到2012年的 Geoff Hinton 团队的深度学习打败Google的标示性事件前，图模型的思想横扫计算机视觉领域（超越了boosting，SVM等）。这使得深度学习生存艰难，没有多少同行在研究中使用深度学习，更多年轻学生愿意去“时髦”的机器学习研究组。

2006年，Yann Lecun的文章还在阐述深度学习如何能跟当年流行的图模型（比如条件随机场模型）等价，证明自己的工作在不同数据集上也能和图模型做到相当的识别精度。尽管在2012年末，Alex Krizhevsky、Ilya Sutskever 两个“小毛孩”在竞赛中用深度学习打败了Google团队，工业界炸锅。但是，工业界对深度学习的追捧传递回学术界发生在一年以后 ，原因是， 除了顶级教授因为私人关系能知道工业界最前沿进展，大部分学术界教授并没有公开渠道及时获取信息，但这些教授却是学术工作评审的主力。因此，直到2013年，Yann Lecun 的文章在计算机视觉的顶级会议上（CVPR）依然很难发表（这时的深度学习在多项数据集上相比其他“传统”方法并不排他性的出色）。

Yann Lecun 像战士一下对抗着学术界的“庸俗”和“传统”，在不同场合讨伐从业人员的态度、标准和品味，公开发文抵制计算机视觉顶级会议CVPR，并于2013年创办了新的学术文章发布体系（ICLR）。可笑的是，仅仅不到两年的时间，现在，视觉的文章没用上深度学习很难发表。主流（不见得创造历史）的和最需要独立思想和自由批判精神的年轻学者，却似乎没有节操的要和深度学习沾上边（当上“千”个博士生都在研究深度学习的时候，应该不需要什么独立见解和勇气）。今天，反而是三十年后卷土重来的Yann Lecun（还有Bengio，Geoff Hinton）愿意站在先锋，批判性的谈论深度学习的泡沫繁荣，呼吁学术界、资金拥有者冷静。反差很是让人感慨。

![Image title](http://a.36krcnd.com/nil_class/1ed3d6ae-9c4d-4a3f-973f-73de46edc4ee/_____2015-06-15___8.58.43.png)

 上图为Yoshua Bengio

到底当时，Yann Lecun 和 Geoff Hinton的团队细微差别在哪呢？高手也可能错过什么呢？或许我们很难有接近事实的答案，原因可能很复杂；但技术上的分解（下次我会撰文就这个问题专门讨论一下，期待有兴趣的朋友和我共同交流，邮箱：leo@yitu-inc.com）。以及对于历史的真实解读才有助于我们抛开浮华，启发一样追求创新的我们，无论是学术研究还是创业。 

> 附：作者和深度学习的关系：作者 Leo 是依图科技CEO，也是加州大学洛杉矶分校（UCLA）统计学博士，师从 Alan Yuille 教授，思想上属于 Bayesian 理念，继承大师 Stuart Geman（美国数学家，科学院院士, 他和弟弟在84年的马尔科夫随机场奠基性工作，足足影响了之后三十年的科研历史）、David Mumford（美国数学家，74年菲尔兹奖得主）和概率学大师Ulf Grenander开创的 Pattern Theory 学派（这些数学家的工作大大早于计算机领域的图模型）。创立依图前，作者在 Yann Lecun 的实验室研究图模型和深度学习的关系，可以从不同视角看深度学习。
